<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Do More with Twitter Data &#8212; Do more with Twitter data 0.1 documentation</title>
    
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          Do more with Twitter data</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="https://github.com/twitterdev/do_more_with_twitter_data">Github</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Do More with Twitter Data</a></li>
<li><a class="reference internal" href="#clustering-twitter-users"><em>Clustering Twitter Users</em></a><ul>
<li><a class="reference internal" href="#intro">Intro</a></li>
<li><a class="reference internal" href="#running-this-notebook">Running This Notebook</a></li>
<li><a class="reference internal" href="#environment-setup">Environment Setup</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-collection">Data Collection</a></li>
<li><a class="reference internal" href="#data-inspection">Data Inspection</a></li>
<li><a class="reference internal" href="#feature-engineering">Feature Engineering</a><ul>
<li><a class="reference internal" href="#source-data">Source data</a></li>
<li><a class="reference internal" href="#preprocessing">Preprocessing</a></li>
<li><a class="reference internal" href="#handling-urls">Handling URLs</a></li>
<li><a class="reference internal" href="#tokenization">Tokenization</a></li>
<li><a class="reference internal" href="#remove-stopwords">Remove Stopwords</a></li>
<li><a class="reference internal" href="#vectorization">Vectorization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#selecting-and-tuning-a-model">Selecting and tuning a model</a></li>
<li><a class="reference internal" href="#inspecting-model-results">Inspecting model results</a><ul>
<li><a class="reference internal" href="#cluster-text-association">Cluster-text association</a></li>
<li><a class="reference internal" href="#visualization">Visualization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-iteration">Model iteration</a><ul>
<li><a class="reference internal" href="#hdbscan">HDBSCAN</a></li>
<li><a class="reference internal" href="#populations-sizes">Populations sizes</a></li>
<li><a class="reference internal" href="#id1">Cluster-text association</a></li>
<li><a class="reference internal" href="#id2">Visualization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</ul>
</li>
              
            
            
              
                
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="do-more-with-twitter-data">
<span id="clustering-users-checkpoint"></span><h1>Do More with Twitter Data<a class="headerlink" href="#do-more-with-twitter-data" title="Permalink to this headline">¬∂</a></h1>
<p>Twitter is what&#8217;s happening and what people are talking about right now,
with hundreds of millions of Tweets sent each day. We&#8217;re a group of data
scientists on the Twitter Data team who are helping people do more with
this vast amount of data in less time. In this spirit, we are starting a
series of tutorials that aim to help people work with Twitter data
effectively. Each of the posts in this series centers around a real-life
example project and provides MIT-licensed code that you can use to
bootstrap your projects with our enterprise and premium API products. We
hope this series is fruitful for you and we are excited to see what
you&#8217;ll build.</p>
</div>
<div class="section" id="clustering-twitter-users">
<h1><em>Clustering Twitter Users</em><a class="headerlink" href="#clustering-twitter-users" title="Permalink to this headline">¬∂</a></h1>
<p>&#8211; by Josh Montague, &#64;<a class="reference external" href="https://twitter.com/jrmontag/">jrmontag</a>,
Data Scientist at Twitter, Feb 2018</p>
<div class="section" id="intro">
<h2>Intro<a class="headerlink" href="#intro" title="Permalink to this headline">¬∂</a></h2>
<p>Often, when people think about conducting analysis on data from Twitter,
they think analyzing Tweet content. While this is a rich collection of
data, another important dimension in which to think about Twitter data
analysis is that of its <em>users</em>.</p>
<p>Twitter users post all sorts of interesting content in Tweets, but they
also frequently share information about themselves by way of their
account profile. If you visit <a class="reference external" href="https://twitter.com/jrmontag">this author&#8217;s
profile</a>, you&#8217;ll find a handful of data
points that are not Tweet-related, but user-related. Among other things,
you might find geographical data, pointers to other websites, and a
free-text profile description e.g. &#8220;counts üê•üí¨, drinks ‚òïÔ∏è, takes üì∑,
climbs üóª&#8221;. This is data that a user may not regularly Tweet about, and
which you would miss if you were only looking at their posted content.</p>
<p>In this demo, we&#8217;re going to look at how to use the Twitter Search APIs
to collect data around a cultural topic, and then use the resulting data
to learn something interesting about the users participating in that
discussion. Specifically, we&#8217;ll look for clusters of similar users among
all of the users we identify. Along the way, we&#8217;ll look at some of the
ways that you can make the journey from the collection of JSON data,
processing relevant elements of each Tweet, engineering features that
can be used for model training, and finally, inspecting the results of
our models to see what we&#8217;ve learned.</p>
<p><strong>Caveat</strong></p>
<p>This post is not meant to be a tutorial in Python or the PyData
ecosystem and assumes that readers have a reasonable amount of technical
sophistication. This tutorial uses Python because our group makes heavy
use of the PyData stack (python, pandas, numpy, scikit-learn, etc.), but
the following techniques can be applied in any language with decent
machine-learning and data processing library support.</p>
<p>This notebook will follow the outline below:</p>
<ul class="simple">
<li>data collection</li>
<li>data inspection</li>
<li>feature engineering<ul>
<li>source data</li>
<li>preprocessing</li>
<li>tokenization</li>
<li>stopwords</li>
<li>vectorization</li>
</ul>
</li>
<li>selecting and tuning a model</li>
<li>inspecting a model</li>
<li>model iteration</li>
</ul>
</div>
<div class="section" id="running-this-notebook">
<h2>Running This Notebook<a class="headerlink" href="#running-this-notebook" title="Permalink to this headline">¬∂</a></h2>
<p>If you want to run this notebook, it is hosted
<a class="reference external" href="https://github.com/twitterdev/learning_more_with_twitter_data">here</a>.
Clone this repo and you&#8217;ll see this notebook in the <code class="docutils literal"><span class="pre">clustering-users</span></code>
directory. Please see the accompanying <code class="docutils literal"><span class="pre">README.md</span></code> file for full
instructions. We&#8217;ve provided both a pip-ready
<code class="docutils literal"><span class="pre">clustering_requirements.txt</span></code> file and a conda environment file,
<code class="docutils literal"><span class="pre">clustering_users_conda_env.yml</span></code> that allows an easy virtual
environment for this example. This example assumes python 3.6.</p>
</div>
<div class="section" id="environment-setup">
<h2>Environment Setup<a class="headerlink" href="#environment-setup" title="Permalink to this headline">¬∂</a></h2>
<p>First, some imports.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">itertools</span> <span class="k">as</span> <span class="nn">it</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">bokeh.plotting</span> <span class="k">import</span> <span class="n">figure</span><span class="p">,</span> <span class="n">ColumnDataSource</span><span class="p">,</span> <span class="n">show</span><span class="p">,</span> <span class="n">output_notebook</span><span class="p">;</span> <span class="n">output_notebook</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">bokeh.models</span> <span class="k">import</span> <span class="n">HoverTool</span>
<span class="kn">from</span> <span class="nn">bokeh.palettes</span> <span class="k">import</span> <span class="n">brewer</span><span class="p">,</span> <span class="n">Viridis256</span>
<span class="kn">import</span> <span class="nn">hdbscan</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="k">import</span> <span class="n">everygrams</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize.casual</span> <span class="k">import</span> <span class="n">TweetTokenizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="k">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">silhouette_score</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">TruncatedSVD</span>
<span class="kn">from</span> <span class="nn">stop_words</span> <span class="k">import</span> <span class="n">get_stop_words</span>
<span class="kn">from</span> <span class="nn">tweet_parser.tweet</span> <span class="k">import</span> <span class="n">Tweet</span>
<span class="kn">from</span> <span class="nn">searchtweets</span> <span class="k">import</span> <span class="n">load_credentials</span><span class="p">,</span> <span class="n">gen_rule_payload</span><span class="p">,</span> <span class="n">collect_results</span>
<span class="kn">from</span> <span class="nn">MulticoreTSNE</span> <span class="k">import</span> <span class="n">MulticoreTSNE</span> <span class="k">as</span> <span class="n">TSNE</span>
<span class="kn">import</span> <span class="nn">yaml</span>

<span class="c1"># better viewing of tweet text</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>

<span class="c1"># reproducible rng</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;bmh&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>
</div>
<div class="bk-root">
    <a href="http://bokeh.pydata.org" target="_blank" class="bk-logo bk-logo-small bk-logo-notebook"></a>
    <span id="17c6c118-48ee-4351-a3d2-7e2b99b0e42c">Loading BokehJS ...</span>
</div></div>
</div>
<div class="section" id="data-collection">
<h1>Data Collection<a class="headerlink" href="#data-collection" title="Permalink to this headline">¬∂</a></h1>
<p>For a detailed walk-through of how to interact with the Search APIs, how
to construct filters, and more of the nuances of iterative
filter-building, you should first review <a class="reference external" href="TODO">this notebook</a>. In
this example, we&#8217;ll assume the reader has enough familiarity that we can
quickly choose a topic, create our first rule, and programatically
interacting with the API to refine the rule.</p>
<p>We&#8217;ll use the <a class="reference external" href="https://en.wikipedia.org/wiki/Cannes_Film_Festival">2017 Cannes Film
Festival</a> as our
topic. Ultimately we are interested in those users who are Tweeting
about the festival, so we start by looking for relevant Tweets and then
we&#8217;ll dig into the users behind those Tweets.</p>
<p>When in doubt, it&#8217;s a reasonable strategy to start broad and simple with
our rule - in this case we can simply use &#8220;cannes&#8221;. After inspecting the
data we can refine the rule (and resulting data) in the name of
increasing it&#8217;s relevance to the task at hand.</p>
<p><strong>Credentials</strong></p>
<p>Please go ahead and make a YAML file named <code class="docutils literal"><span class="pre">.twitter_keys.yaml</span></code> in
your home directory.</p>
<p>For premium customers, the simplest credential file should look like
this:</p>
<div class="code yaml highlight-default"><div class="highlight"><pre><span></span><span class="n">search_tweets_api</span><span class="p">:</span>
  <span class="n">account_type</span><span class="p">:</span> <span class="n">premium</span>
  <span class="n">endpoint</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">FULL_URL_OF_ENDPOINT</span><span class="o">&gt;</span>
  <span class="n">consumer_key</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">CONSUMER_KEY</span><span class="o">&gt;</span>
  <span class="n">consumer_secret</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">CONSUMER_SECRET</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>For enterprise customers, the simplest credential file should look like
this:</p>
<div class="code yaml highlight-default"><div class="highlight"><pre><span></span><span class="n">search_tweets_api</span><span class="p">:</span>
  <span class="n">account_type</span><span class="p">:</span> <span class="n">enterprise</span>
  <span class="n">endpoint</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">FULL_URL_OF_ENDPOINT</span><span class="o">&gt;</span>
  <span class="n">username</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">USERNAME</span><span class="o">&gt;</span>
  <span class="n">password</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">PW</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>The rest of the example will assume <code class="docutils literal"><span class="pre">~/.twitter_keys.yaml</span></code> exists,
though you can specify your connection information directing in the
notebook or using an environment variable if you want. For more
information, please see the <code class="docutils literal"><span class="pre">searchtweets</span></code> <a class="reference external" href="https://twitterdev.github.io/search-tweets-python/#credential-handling">section on credential
handling</a>.</p>
<p>The <code class="docutils literal"><span class="pre">load_credentials</span></code> function parses this file and we&#8217;ll save the
<code class="docutils literal"><span class="pre">search_args</span></code> variable for use throughout the session.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">search_args</span> <span class="o">=</span> <span class="n">load_credentials</span><span class="p">(</span><span class="n">account_type</span><span class="o">=</span><span class="s2">&quot;enterprise&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The 2017 festival lasted from 2017-05-17 to 2017-05-29. Our simple rule
will likely generate a lot of data in that time range, so we&#8217;ll limit
our queries by the number of Tweets to start. We can still use these
dates in our rule, and later we&#8217;ll just adjust the Tweet limit.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># the festival was 2017-05-17 -- 2017-05-29</span>
<span class="n">rule</span> <span class="o">=</span> <span class="n">gen_rule_payload</span><span class="p">(</span><span class="s1">&#39;cannes&#39;</span><span class="p">,</span> <span class="n">from_date</span><span class="o">=</span><span class="s1">&#39;2017-05-17&#39;</span><span class="p">,</span> <span class="n">to_date</span><span class="o">=</span><span class="s1">&#39;2017-05-29&#39;</span><span class="p">)</span>

<span class="n">rule</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;{&quot;query&quot;:&quot;cannes&quot;,&quot;maxResults&quot;:500,&quot;toDate&quot;:&quot;201705290000&quot;,&quot;fromDate&quot;:&quot;201705170000&quot;}&#39;</span>
</pre></div>
</div>
<p>We can pass the rule and our limit of 1000 Tweets to the API, and
collect the results into memory. For convenience, we&#8217;ll also write them
to disk as newline-delimited JSON, too. This is handy in case we want to
come back to the same data later - we won&#8217;t need to make new API
requests.</p>
<p>The following function will define our entry point to get our Tweet
data, and will automatically read or collect the data from the API and
save it to the passed filename.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">maybe_get_tweets</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_results</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">tweets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">infile</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;reading cached tweets&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">infile</span><span class="p">:</span>
                <span class="n">tweets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Tweet</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">)))</span>

    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">rule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;collecting tweets from the API&quot;</span><span class="p">)</span>
            <span class="n">tweets</span> <span class="o">=</span> <span class="n">collect_results</span><span class="p">(</span><span class="n">rule</span><span class="p">,</span>
                                     <span class="n">max_results</span><span class="o">=</span><span class="n">max_results</span><span class="p">,</span>
                                     <span class="n">result_stream_args</span><span class="o">=</span><span class="n">search_args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;rule is not defined; please supply a valid rule for the query&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">KeyError</span>
        <span class="c1"># write sample to disk</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">outfile</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">tw</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">:</span>
                <span class="n">outfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">tw</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tweets</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tweets</span> <span class="o">=</span> <span class="n">maybe_get_tweets</span><span class="p">(</span><span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;data/sample-cannes.json&quot;</span><span class="p">,</span> <span class="n">rule</span><span class="o">=</span><span class="n">rule</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">reading</span> <span class="n">cached</span> <span class="n">tweets</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">1000</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># quick check of one payload</span>
<span class="n">tweets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;RT @PurelyPattinson: NEW pictures of Rob in Cannes last night. (Via @AboutRPattinson) https://t.co/w5P7PilHwc&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="data-inspection">
<h1>Data Inspection<a class="headerlink" href="#data-inspection" title="Permalink to this headline">¬∂</a></h1>
<p>Great, now we have some data to work with. Importantly, the first step
is always to inspect the data. Is it what you were expecting? Is it
relevant? Are there sources of noise you can negate in your rule? All of
these issues can be addressed by iterating on your filters and
inspecting the results.</p>
<p>Additionally, since we intentionally capped the number of total Tweets,
it&#8217;s good to inspect the time series of data to see what range it
covers.</p>
<p>Since Tweets are automatically parsed with the <a class="reference external" href="https://tw-ddis.github.io/tweet_parser/index.html">Tweet
Parser</a> in our
Python session, we can use some of the convenient attributes to pull out
the text data.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tweets_to_df</span><span class="p">(</span><span class="n">tweets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper func to extract specific tweet features into a dataframe.&quot;&quot;&quot;</span>
    <span class="n">tweet_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;ts&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">created_at_datetime</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">],</span>
                             <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">all_text</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">],</span>
                             <span class="s1">&#39;uid&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">user_id</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">],}</span>
                           <span class="p">)</span>
    <span class="c1"># creating a datetimeindex will allow us to do more timeseries manipulations</span>
    <span class="n">tweet_df</span><span class="p">[</span><span class="s1">&#39;ts&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">tweet_df</span><span class="p">[</span><span class="s1">&#39;ts&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tweet_df</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tweet_df</span> <span class="o">=</span> <span class="n">tweets_to_df</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>

<span class="n">tweet_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>ts</th>
      <th>uid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NEW pictures of Rob in Cannes last night. (Via @AboutRPattinson) https://t.co/w5P7PilHwc</td>
      <td>2017-05-28 23:59:58</td>
      <td>711474468</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Hasta hoy solo dos mujeres ganaron el premio a la mejor direcci√≥n en Cannes... https://t.co/0dYh2OrsDS #lacosacine</td>
      <td>2017-05-28 23:59:58</td>
      <td>153826105</td>
    </tr>
    <tr>
      <th>2</th>
      <td>juliette binoche wearing armani dresses at cannes,, rt if you agree https://t.co/vAuXtjjxZv</td>
      <td>2017-05-28 23:59:56</td>
      <td>3179550766</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Aishwarya Rai Bachchan is the Queen of the Cannes Film Festival üëëüëëüëë https://t.co/sLsIwxDWFw</td>
      <td>2017-05-28 23:59:54</td>
      <td>314300800</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Cannes Film Festival\n‚ÄòThe Square‚Äô Wins Top Prize at @Festival_Cannes\nSofia Coppola ("The Beguiled") Is Best Director\nhttps://t.co/RZilOXxQcV ht...</td>
      <td>2017-05-28 23:59:54</td>
      <td>713888098313224192</td>
    </tr>
  </tbody>
</table>
</div><div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># plot a time series</span>
<span class="p">(</span><span class="n">tweet_df</span><span class="p">[[</span><span class="s1">&#39;ts&#39;</span><span class="p">,</span><span class="s1">&#39;text&#39;</span><span class="p">]]</span>
 <span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;ts&#39;</span><span class="p">)</span>
 <span class="c1"># &#39;T&#39; = minute</span>
 <span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
 <span class="o">.</span><span class="n">count</span><span class="p">()</span>
 <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;1-minute counts&#39;</span><span class="p">))</span>
 <span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="p">);</span>
</pre></div>
</div>
<img alt="_images/clustering-users-checkpoint_16_0.png" src="_images/clustering-users-checkpoint_16_0.png" />
<p>Given the <code class="docutils literal"><span class="pre">max_results</span></code> we added, we have a very short time span for
now. Our data collection starts at the end date, and works backward
until hitting the maximum result count. But that&#8217;s ok, we&#8217;ll collect
more data later. For a much more thorough discussion of how to work with
Tweets as a time series, be sure to read our forthcoming tutorial.</p>
<p>With this small sample, let&#8217;s do a bit of rough text processing to look
at the text we&#8217;re seeing in these Tweets. A simple - and often,
informative - first way to inspect the content of text data is through
looking at the most common n-grams. In language modeling, an &#8220;n-gram&#8221; is
a contiguous collection of some <em>n</em> items - in languages where
appropriate, this is often white-space separated words. For example,
two-grams in the sentence &#8220;The dog ate my homework&#8221; would be &#8220;the dog&#8221;,
&#8220;dog ate&#8221;, &#8220;ate my&#8221;, &#8220;my homework&#8221;.</p>
<p>We&#8217;ll use the <code class="docutils literal"><span class="pre">all_text</span></code> attribute of our Tweet objects to simply pull
in all the text, regardless of whether it was a Retweet, original Tweet,
or Quote Tweet. Then we&#8217;ll concatenate all the Tweet text together (from
the whole corpus), split it up into words using an open-source tokenizer
from NLTK (we&#8217;ll talk more about this, shortly), remove some
punctuation, and then simply count the most common set of n-grams.</p>
<p>This is a very rough (but quick) way of getting a feel for the text data
we have. If we see content that we don&#8217;t think is relevant, we can go
back and modify our rule.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_all_tokens</span><span class="p">(</span><span class="n">tweet_list</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to generate a list of text tokens from concatenating</span>
<span class="sd">    all of the text contained in Tweets in `tweet_list`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># concat entire corpus</span>
    <span class="n">all_text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">((</span><span class="n">t</span><span class="o">.</span><span class="n">all_text</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">))</span>
    <span class="c1"># tokenize</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">(</span><span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">preserve_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">strip_handles</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
              <span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">all_text</span><span class="p">))</span>
    <span class="c1"># remove symbol-only tokens for now</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">tok</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">tokens</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">get_all_tokens</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total number of tokens: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">total</span> <span class="n">number</span> <span class="n">of</span> <span class="n">tokens</span><span class="p">:</span> <span class="mi">16160</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># calculate a range of ngrams using some handy functions</span>
<span class="n">top_grams</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">everygrams</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>

<span class="n">top_grams</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[((</span><span class="s1">&#39;sofia&#39;</span><span class="p">,</span> <span class="s1">&#39;coppola&#39;</span><span class="p">),</span> <span class="mi">216</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">),</span> <span class="mi">198</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;at&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">145</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;win&#39;</span><span class="p">),</span> <span class="mi">140</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">),</span> <span class="mi">121</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;cannes&#39;</span><span class="p">,</span> <span class="s1">&#39;film&#39;</span><span class="p">),</span> <span class="mi">117</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">),</span> <span class="mi">116</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">),</span> <span class="mi">116</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;film&#39;</span><span class="p">,</span> <span class="s1">&#39;festival&#39;</span><span class="p">),</span> <span class="mi">109</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">),</span> <span class="mi">107</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;cannes&#39;</span><span class="p">,</span> <span class="s1">&#39;film&#39;</span><span class="p">,</span> <span class="s1">&#39;festival&#39;</span><span class="p">),</span> <span class="mi">106</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">),</span> <span class="mi">105</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">),</span> <span class="mi">104</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">),</span> <span class="mi">104</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;de&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">96</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;cannes&#39;</span><span class="p">,</span> <span class="s1">&#39;2017&#39;</span><span class="p">),</span> <span class="mi">84</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">78</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;win&#39;</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">),</span> <span class="mi">76</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">),</span> <span class="mi">75</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;en&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">73</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">70</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">,</span> <span class="s1">&#39;at&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">70</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;win&#39;</span><span class="p">),</span> <span class="mi">69</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;second&#39;</span><span class="p">),</span> <span class="mi">67</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;festival&#39;</span><span class="p">,</span> <span class="s1">&#39;de&#39;</span><span class="p">),</span> <span class="mi">61</span><span class="p">)]</span>
</pre></div>
</div>
<p>Using these top n-grams, we can see the phrases &#8220;sofia coppola&#8221; and
&#8220;best director&#8221; were very common at the event. If you don&#8217;t happen to be
familiar with the film industry, you may want to inspect those terms a
bit more to understand their context.</p>
<p>We can go back to the Dataframe and filter on one of those terms to see
what the original content was about.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># create a filter series matching &quot;coppola&quot;</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">tweet_df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;coppola&quot;</span><span class="p">)</span>

<span class="c1"># look at text only from matching rows</span>
<span class="n">tweet_df</span><span class="p">[</span><span class="n">mask</span><span class="p">][[</span><span class="s1">&#39;text&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>Cannes Film Festival\n‚ÄòThe Square‚Äô Wins Top Prize at @Festival_Cannes\nSofia Coppola ("The Beguiled") Is Best Director\nhttps://t.co/RZilOXxQcV ht...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The last woman to win Best Director at Cannes was Yuliya Solntseva in 1961 for The Story of the Flaming Years. And now Coppola #Cannes2017 https:/...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Congrats to Hillary supporter Sofia Coppola for being only the 2nd woman to win Best Director at the Cannes Film Festival for THE BEGUILED. https:...</td>
    </tr>
    <tr>
      <th>10</th>
      <td>The only female BEST DIRECTOR winners at Cannes in its 70 year history. Both started as actresses: Yuliya Solntseva &amp;amp; Sofia Coppola https://t....</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Coppola/Cannes story is a reminder that if women directors were given equal opportunity more would win. Lots of talented female filmmakers.</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Sofia Coppola becomes the second woman in history to score #Cannes Best Director prize https://t.co/bqiU0ho34o https://t.co/pL73nmHxz4</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Yes @jazzt Let's Celebrate the Best Director @Festival_Cannes #SofiaCoppola for #TheBeguiled We can't wait to see it. \nWOMEN RULE https://t.co/wr...</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Critics are calling Sofia Coppola‚Äôs #TheBeguiled a ‚Äúhilariously fraught feminist psychodrama‚Äù: https://t.co/kM3c5SXiui</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Sofia Coppola is 1st woman to win Best Director at #cannes in 56 years. Jane Campion still only woman to win Palme d'Or. 70 yrs &amp;amp; counting</td>
    </tr>
    <tr>
      <th>46</th>
      <td>https://t.co/U0pNCd2exR #unsigned #talent #forum\n\nCritics are calling Sofia Coppola‚Äôs #TheBeguiled a ‚Äúhilariously‚Ä¶ https://t.co/IlekTpP9Yg</td>
    </tr>
  </tbody>
</table>
</div><p>Ah-ha, it appears Sofia Coppola&#8217;s win as the festival&#8217;s &#8220;Best Director&#8221;
was an historic event (the curious can read about it
<a class="reference external" href="http://www.cnn.com/2017/05/29/entertainment/cannes-sofia-coppola/index.html">here</a>).</p>
<p>These Tweets seem on-topic, and the most common tokens don&#8217;t appear to
have much noise. Since our rule seems to be pretty good, let&#8217;s use it -
unchanged - to collect a bunch more data before we carry on with our
modeling task.</p>
<p>You should be able to run the rest of the analysis below with
<code class="docutils literal"><span class="pre">max_results=20000</span></code> if on a modern laptop with 16 GB of RAM. But if
you run into memory or time constraints, you can always turn down
<code class="docutils literal"><span class="pre">max_results</span></code> and still run the rest of the analysis (or move this
over to a bigger virtual instance if that&#8217;s more your thing).</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tweets</span> <span class="o">=</span> <span class="n">maybe_get_tweets</span><span class="p">(</span><span class="n">file_name</span><span class="o">=</span><span class="s2">&quot;data/larger-cannes.json&quot;</span><span class="p">,</span>
                          <span class="n">rule</span><span class="o">=</span><span class="n">rule</span><span class="p">,</span>
                          <span class="n">max_results</span><span class="o">=</span><span class="mi">20000</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">reading</span> <span class="n">cached</span> <span class="n">tweets</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">50000</span>
</pre></div>
</div>
<p>Let&#8217;s do our quick inspection process again. We&#8217;ll print out our n-grams
and a time-series plot of minute-duration counts.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># ngrams</span>
<span class="n">Counter</span><span class="p">(</span><span class="n">everygrams</span><span class="p">(</span><span class="n">get_all_tokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[((</span><span class="s1">&#39;cannes&#39;</span><span class="p">,),</span> <span class="mi">32927</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;the&#39;</span><span class="p">,),</span> <span class="mi">27781</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;de&#39;</span><span class="p">,),</span> <span class="mi">16583</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;#cannes2017&#39;</span><span class="p">,),</span> <span class="mi">13598</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;at&#39;</span><span class="p">,),</span> <span class="mi">10778</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;coppola&#39;</span><span class="p">,),</span> <span class="mi">10132</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,),</span> <span class="mi">10023</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;sofia&#39;</span><span class="p">,),</span> <span class="mi">9545</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;square&#39;</span><span class="p">,),</span> <span class="mi">9475</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">),</span> <span class="mi">9453</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;sofia&#39;</span><span class="p">,</span> <span class="s1">&#39;coppola&#39;</span><span class="p">),</span> <span class="mi">9064</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;to&#39;</span><span class="p">,),</span> <span class="mi">9013</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;director&#39;</span><span class="p">,),</span> <span class="mi">9010</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;festival&#39;</span><span class="p">,),</span> <span class="mi">8708</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;la&#39;</span><span class="p">,),</span> <span class="mi">8638</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;in&#39;</span><span class="p">,),</span> <span class="mi">8439</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;director&#39;</span><span class="p">),</span> <span class="mi">7731</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;palme&#39;</span><span class="p">,),</span> <span class="mi">7224</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;a&#39;</span><span class="p">,),</span> <span class="mi">7107</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;film&#39;</span><span class="p">,),</span> <span class="mi">6943</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;wins&#39;</span><span class="p">,),</span> <span class="mi">6695</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;en&#39;</span><span class="p">,),</span> <span class="mi">6462</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;at&#39;</span><span class="p">,</span> <span class="s1">&#39;cannes&#39;</span><span class="p">),</span> <span class="mi">6428</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;win&#39;</span><span class="p">,),</span> <span class="mi">6030</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;du&#39;</span><span class="p">,),</span> <span class="mi">5754</span><span class="p">)]</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># time series</span>
<span class="n">tweet_df</span> <span class="o">=</span> <span class="n">tweets_to_df</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>

<span class="p">(</span><span class="n">tweet_df</span><span class="p">[[</span><span class="s1">&#39;ts&#39;</span><span class="p">,</span><span class="s1">&#39;text&#39;</span><span class="p">]]</span>
 <span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;ts&#39;</span><span class="p">)</span>
 <span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">)</span>
 <span class="o">.</span><span class="n">count</span><span class="p">()</span>
 <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;minute counts&#39;</span><span class="p">))</span>
 <span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="p">);</span>
</pre></div>
</div>
<img alt="_images/clustering-users-checkpoint_28_0.png" src="_images/clustering-users-checkpoint_28_0.png" />
<p>Now we can see that our first query was way out in the small tail of
data volume (to the right in our chart, toward the chosen end date). Our
query now moves further back into the large-volume region. Even with a
Tweet count limit of many thousands, we&#8217;re still only covering a few
hours of the last day!</p>
<p>Given both the narrow timeframe and Coppola&#8217;s historic win, it&#8217;s
possible that our data collection will be heavily weighted toward that
topic. If we collected all the data back to the beginning of the
festival, we would likely see additional topics surface in our analysis,
and possibly better represent the full breadth of discussion around the
festival.</p>
<p>Nevertheless, we can still move forward with our modeling. Let&#8217;s set the
stage by asking, simply: how many users are we looking at?</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">unique_user_cnt</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">tweet_df</span><span class="p">[</span><span class="s1">&#39;uid&#39;</span><span class="p">]))</span>

<span class="n">unique_user_cnt</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">30819</span>
</pre></div>
</div>
<p>Now that we have a bunch of useful data, let&#8217;s see what kinds of groups
of users we can identify in this collection.</p>
<p>The first thing we&#8217;ll do is step back to reconsider those rudimentary
processing procedures we just used, and add some sophistication.</p>
</div>
<div class="section" id="feature-engineering">
<h1>Feature Engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this headline">¬∂</a></h1>
<p>This notebook isn&#8217;t intended to be a general tutorial in feature
engineering or ML model development. But there are some nuances and
choices in how we make the transition from semi-structured (JSON)
Twitter data to the common two-dimensional data matrix of observations
and features that many off-the-shelf machine learning libraries expect.</p>
<p>Domain-specific feature engineering often involves a bit of exploratory
analysis and domain knowledge relevant to the discipline. While we&#8217;re
not going to demonstrate all of that process here, we will instead aim
to touch on the main points, and also to point out the steps where the
reader should take time to consider how their own use cases inform
alternative choices.</p>
<div class="section" id="source-data">
<h2>Source data<a class="headerlink" href="#source-data" title="Permalink to this headline">¬∂</a></h2>
<p>First off, we&#8217;ll identify the particular pieces of data from the Tweet
to be used in our model. Recall that the JSON payload from a single
Tweet can have more than 100 key-value pairs.</p>
<p>We&#8217;re going to apply clustering algorithms (a form of unsupervised
learning) to a set of users and some of the text data that represents
them, and there are many ways of consolidating some amount of data to
represent a single user. You could use the users&#8217; most recent (single)
Tweet, their most recent 30-days worth of Tweets (concatenated in one
long string), you could pull out all of the URLs users shared, or the
other users that they mentioned explicitly in their Tweets.</p>
<p>For this example, we&#8217;ll represent each user by the free-form text field
that the user manually enters in their profile to describe themselves,
commonly called the &#8220;user bio&#8221; or the &#8220;bio.&#8221;</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># pick a single random tweet</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">51</span>

<span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">screen_name</span><span class="p">,</span> <span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bio</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="s1">&#39;üéÑSugarPlumFairyüéÑ&#39;</span><span class="p">,</span>
 <span class="s1">&#39;msgoddessrises&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Film/Writer #DivineIntervention #DivineProvidence #independent #MS Saving the world 1 tweet at a time #VegasStrong üôèüèª‚ù§Ô∏èüé≤üóΩüé¢üé°üé∞#GodsInControl. #NeverTrump&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">¬∂</a></h2>
<p>User-generated text often has quirks and oddities. Even beyond the
design and constraints of a particular user interface, text data can
<a class="reference external" href="https://twitter.com/FakeUnicode">just be difficult</a>. Furthermore,
anytime a platform creates a new phenomena like <code class="docutils literal"><span class="pre">#hashtags</span></code>,
<code class="docutils literal"><span class="pre">&#64;mentions</span></code>, <code class="docutils literal"><span class="pre">$cashtags</span></code>, or the ability to attach media, it
introduces unique patterns of characters into the associated text
fields.</p>
<p>One of the key steps in collecting, processing, and analyzing data from
such a platform is properly accounting for these unique types of data
using the relevant domain knowledge. This collection of tasks is one
that we commonly refer to as <em>preprocessing</em> because it occurs prior to
the data being input to any model.</p>
<p>Choices about how much, and what type, of preprocessing to apply are
subjective. Ideally, you should try to evaluate the effect of varying
choices on the metrics you care about - things like click through rate,
transactions, new customer acquisition, etc. Here, we&#8217;ll demonstrate a
few common examples of preprocessing a user-input text string before it
gets to a model.</p>
</div>
<div class="section" id="handling-urls">
<h2>Handling URLs<a class="headerlink" href="#handling-urls" title="Permalink to this headline">¬∂</a></h2>
<p>A common issue in working with Tweet text is that user-entered URLs will
be run through <a class="reference external" href="https://support.twitter.com/articles/109623">a link
shortener</a>.
Additionally, the user may have <em>also</em> used a link shortener like
<code class="docutils literal"><span class="pre">bit.ly</span></code> for the added analytics. In either case, the literal URL
string we see likely doesn&#8217;t contain much useful information and it will
also lead to an unhelpful excess of low-frequency &#8220;words&#8221; in our
eventual data matrix. Note that while shortened URLs are not
particularly useful (because they&#8217;re typically some form of hash),
&#8220;unrolled URLs&#8221; (i.e. the fully expanded URLs to which the shortened
URLS redirect) can actually provide useful signal e.g. a .org TLD might
signal a business&#8217; website instead of a personal one.</p>
<p>To address this problem, we&#8217;ll strip URLs from the original text with <a class="reference external" href="https://www.bit.ly/PyURLre">a
relatively simple regular expression</a> and
optionally replace them with a new string. It doesn&#8217;t much matter what
string you replace the URLs with, as long as it&#8217;s recognizable in your
later analyses. Note that this regex is reasonable, but definitely not
perfect - if you wanted to make it more robust, you certainly can! For
example, this regex also matches anything that is of the form
<code class="docutils literal"><span class="pre">text.text</span></code> (including email addresses)</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">replace_urls</span><span class="p">(</span><span class="n">in_string</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Replace URLs in strings. See also: ``bit.ly/PyURLre``</span>

<span class="sd">    Args:</span>
<span class="sd">        in_string (str): string to filter</span>
<span class="sd">        replacement (str or None): replacment text. defaults to &#39;&lt;-URL-&gt;&#39;</span>

<span class="sd">    Returns:</span>
<span class="sd">        str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">replacement</span> <span class="o">=</span> <span class="s1">&#39;&lt;-URL-&gt;&#39;</span> <span class="k">if</span> <span class="n">replacement</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">replacement</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;(https?://)?(\w*[.]\w+)+([/?=&amp;]+\w+)*&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">replacement</span><span class="p">,</span> <span class="n">in_string</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># add fake url for demonstration</span>
<span class="n">replace_urls</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bio</span> <span class="o">+</span> <span class="s2">&quot; http://bit.ly/4atsdfzc&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;Film/Writer #DivineIntervention #DivineProvidence #independent #MS Saving the world 1 tweet at a time #VegasStrong üôèüèª‚ù§Ô∏èüé≤üóΩüé¢üé°üé∞#GodsInControl. #NeverTrump &lt;-URL-&gt;&#39;</span>
</pre></div>
</div>
<p>If adding a new term to your data set doesn&#8217;t work for your use case,
you could also replace URLs with a whitespace character. In choosing
your replacement token, be sure to take some time to experiment with the
interaction between it any any downstream processing pieces like
tokenizers.</p>
<p>Other forms of preprocessing include translation from one language to
another, character normalization e.g. unicode to ASCII, or any other
transformation that benefits the context of the full string.</p>
</div>
<div class="section" id="tokenization">
<h2>Tokenization<a class="headerlink" href="#tokenization" title="Permalink to this headline">¬∂</a></h2>
<p>An important step in text processing is splitting the string into tokens
(or words). There are many ways to break up a text string into tokens
(and many text-processing and NLP libraries to assist in doing so). For
the sake of this discussion, we&#8217;re mostly going to look at English. In
that case, splitting text on whitespace is the simplest possible way to
do this. Common text vectorizers - <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer">like those in
scikit-learn</a>
- also have slightly fancier tokenizers already built in for you to use
(we&#8217;ll talk more about vectorization, shortly).</p>
<p>We can also choose to create our own explicit tokenizer if the data (and
task) call for it. One particular method that works with Twitter data is
NLTK&#8217;s
<a class="reference external" href="http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.casual.TweetTokenizer">TweetTokenizer</a>.
It does a couple of smart things: preserves <code class="docutils literal"><span class="pre">&#64;</span></code> and <code class="docutils literal"><span class="pre">#</span></code> symbols at
the start of words, and can also &#8220;collapse&#8221; repeated characters - that
is, <code class="docutils literal"><span class="pre">lolll</span></code>, <code class="docutils literal"><span class="pre">lollllll</span></code>, and <code class="docutils literal"><span class="pre">lollllllllllll</span></code> will all collapse to
the same representation <code class="docutils literal"><span class="pre">&quot;lolll&quot;</span></code> (three &#8220;l&#8221;s). This is helpful
because we tend to think that these tokens represent approximately the
same thing. This feature helps curb the curse of dimensionality (i.e.
too many low-frequency tokens), while maintaining Twitter-specific
features.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_tokenizer</span><span class="p">(</span><span class="n">in_string</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert `in_string` of text to a list of tokens using NLTK&#39;s TweetTokenizer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># reasonable, but adjustable tokenizer settings</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">preserve_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">strip_handles</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">in_string</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tokens</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bio</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s1">&#39;Film/Writer #DivineIntervention #DivineProvidence #independent #MS Saving the world 1 tweet at a time #VegasStrong üôèüèª‚ù§Ô∏èüé≤üóΩüé¢üé°üé∞#GodsInControl. #NeverTrump&#39;</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">my_tokenizer</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bio</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;film&#39;</span><span class="p">,</span>
 <span class="s1">&#39;/&#39;</span><span class="p">,</span>
 <span class="s1">&#39;writer&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#divineintervention&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#divineprovidence&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#independent&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#ms&#39;</span><span class="p">,</span>
 <span class="s1">&#39;saving&#39;</span><span class="p">,</span>
 <span class="s1">&#39;the&#39;</span><span class="p">,</span>
 <span class="s1">&#39;world&#39;</span><span class="p">,</span>
 <span class="s1">&#39;1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;tweet&#39;</span><span class="p">,</span>
 <span class="s1">&#39;at&#39;</span><span class="p">,</span>
 <span class="s1">&#39;a&#39;</span><span class="p">,</span>
 <span class="s1">&#39;time&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#vegasstrong&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üôè&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üèª&#39;</span><span class="p">,</span>
 <span class="s1">&#39;‚ù§&#39;</span><span class="p">,</span>
 <span class="s1">&#39;Ô∏è&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üé≤&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üóΩ&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üé¢&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üé°&#39;</span><span class="p">,</span>
 <span class="s1">&#39;üé∞&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#godsincontrol&#39;</span><span class="p">,</span>
 <span class="s1">&#39;.&#39;</span><span class="p">,</span>
 <span class="s1">&#39;#nevertrump&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="remove-stopwords">
<h2>Remove Stopwords<a class="headerlink" href="#remove-stopwords" title="Permalink to this headline">¬∂</a></h2>
<p>Another common processing step involves filtering out words that are
sufficiently common in language that they provide little value. For
example, in English, use of the 1-gram &#8220;the&#8221; is unlikely to provide
valuable signal in a modeling task. Similarly, &#8216;la&#8217; or &#8216;le&#8217; in French.
These words or tokens might actually be useful signal if you&#8217;re trying
to create a text language classifier, but they can also lead us to
overfit a model on low-signal words.</p>
<p>Choosing a domain- and task-relevant list of stopwords is an important
and valuable exercise that does not have a clear-cut, &#8220;correct&#8221; answer.
Many NLP libraries include built-in stopword lists that you can use,
often out-of-the-box e.g. <a class="reference external" href="http://www.nltk.org/nltk_data/">NLTK</a>, and
<a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/stop_words.py">sklearn</a>.
It&#8217;s worth looking into the specific choices that each library makes
with its selection of stopwords to ensure that it aligns with your goals
and expectations for inclusion or removal of content.</p>
<p>Another example that gives the user some fine-grained control over the
words is the <code class="docutils literal"><span class="pre">`python-stop-words</span></code>
library &lt;<a class="reference external" href="https://github.com/Alir3z4/python-stop-words">https://github.com/Alir3z4/python-stop-words</a>&gt;`__. We&#8217;ll use
this library for our demo.</p>
<p>How do we know which languages to add? We can get a good first guess by
counting up the distribution of language classifications in our Tweets.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">Counter</span><span class="p">([</span><span class="n">t</span><span class="o">.</span><span class="n">lang</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">])</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[(</span><span class="s1">&#39;en&#39;</span><span class="p">,</span> <span class="mi">24819</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;fr&#39;</span><span class="p">,</span> <span class="mi">11017</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;es&#39;</span><span class="p">,</span> <span class="mi">6110</span><span class="p">),</span>
 <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1601</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span> <span class="mi">1594</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;de&#39;</span><span class="p">,</span> <span class="mi">1222</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="mi">993</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;tr&#39;</span><span class="p">,</span> <span class="mi">919</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="mi">385</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;sv&#39;</span><span class="p">,</span> <span class="mi">296</span><span class="p">)]</span>
</pre></div>
</div>
<p>It looks like we should consider adding the six or seven languages that
appear in the tall head.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">languages</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;english&#39;</span><span class="p">,</span>
             <span class="s1">&#39;spanish&#39;</span><span class="p">,</span>
             <span class="s1">&#39;portuguese&#39;</span><span class="p">,</span>
             <span class="s1">&#39;german&#39;</span><span class="p">,</span>
             <span class="s1">&#39;french&#39;</span><span class="p">,</span>
             <span class="s1">&#39;italian&#39;</span><span class="p">,</span>
             <span class="s1">&#39;turkish&#39;</span>
            <span class="p">]</span>

<span class="c1"># collect and dedupe</span>
<span class="n">my_stopwords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">((</span><span class="n">get_stop_words</span><span class="p">(</span><span class="n">lang</span><span class="p">)</span>
                                                <span class="k">for</span> <span class="n">lang</span> <span class="ow">in</span> <span class="n">languages</span><span class="p">))))</span>
<span class="nb">len</span><span class="p">(</span><span class="n">my_stopwords</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">1462</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># look at a sample</span>
<span class="n">my_stopwords</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;hai&#39;</span><span class="p">,</span>
 <span class="s2">&quot;she&#39;d&quot;</span><span class="p">,</span>
 <span class="s1">&#39;fuera&#39;</span><span class="p">,</span>
 <span class="s1">&#39;anderen&#39;</span><span class="p">,</span>
 <span class="s1">&#39;faisez&#39;</span><span class="p">,</span>
 <span class="s1">&#39;√©ramos&#39;</span><span class="p">,</span>
 <span class="s1">&#39;because&#39;</span><span class="p">,</span>
 <span class="s1">&#39;tem&#39;</span><span class="p">,</span>
 <span class="s1">&#39;√æunu&#39;</span><span class="p">,</span>
 <span class="s1">&#39;eles&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Additionally, we can filter out some &#8220;punctuation noise&#8221; from our data
by augmenting the stopword list with some commonly occurring, but
low-value, tokens that comprise punctuation, only. For example, we can
trade &#8220;did you see that?!?%*&amp;&#64;#?!&#8221; for &#8220;did you see that&#8221; without
worrying too much about lost signal.</p>
<p>Since there are many punctuation characters (and it would be slow to
iterate over each character in our tokens to check for all-punctuation
tokens), we&#8217;ll make a simple list of &#8220;words&#8221; that comprise only
punctuation and append them to our current stopword list.</p>
<p>There are a couple of handy built-in features we can use to do this in a
compact way.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># ex: length-2 permutations of the given set of chars</span>
<span class="p">[</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">it</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="s1">&#39;#$.&#39;</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">2</span><span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;##&#39;</span><span class="p">,</span> <span class="s1">&#39;#$&#39;</span><span class="p">,</span> <span class="s1">&#39;#.&#39;</span><span class="p">,</span> <span class="s1">&#39;$#&#39;</span><span class="p">,</span> <span class="s1">&#39;$$&#39;</span><span class="p">,</span> <span class="s1">&#39;$.&#39;</span><span class="p">,</span> <span class="s1">&#39;.#&#39;</span><span class="p">,</span> <span class="s1">&#39;.$&#39;</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_punc_stopwords</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates punctuation &#39;words&#39; up to</span>
<span class="sd">    ``max_length`` characters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">punct_maker</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">((</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">it</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">,</span>
                                                <span class="n">repeat</span><span class="o">=</span><span class="n">length</span><span class="p">)))</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">it</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">((</span><span class="n">punct_maker</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">length</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">my_stopwords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="n">my_stopwords</span><span class="p">,</span> <span class="n">make_punc_stopwords</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">4</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;current count of stopwords: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">my_stopwords</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;example punctuation words:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">my_stopwords</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">current</span> <span class="n">count</span> <span class="n">of</span> <span class="n">stopwords</span><span class="p">:</span> <span class="mi">1083863</span>
<span class="n">example</span> <span class="n">punctuation</span> <span class="n">words</span><span class="p">:</span>
 <span class="p">[</span><span class="s1">&#39;~~~[&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~]&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~^&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~_&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~`&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~{&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~|&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~}&#39;</span><span class="p">,</span> <span class="s1">&#39;~~~~&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>At this point, we&#8217;ve added a lot of stopwords! But that should be ok -
most of them were from the punctuation set and should help us focus on
the words that do add signal to the text model. As mentioned before,
it&#8217;s always a good idea to experiment with these choices in your model
development to see if they make sense, or add (or remove!) value from
the metrics you care about.</p>
</div>
<div class="section" id="vectorization">
<h2>Vectorization<a class="headerlink" href="#vectorization" title="Permalink to this headline">¬∂</a></h2>
<p>Most of the available out-of-the-box machine learning algorithms e.g. in
<code class="docutils literal"><span class="pre">sklearn</span></code> expect input in the form of a two-dimensional data matrix of
numerical values: observations (rows) <em>x</em> features (columns). To create
a numerical representation of text data, we need to vectorize the text
features (tokens), and libraries like <code class="docutils literal"><span class="pre">sklearn</span></code> provide many ways to
do this.</p>
<p>For this example, we&#8217;ll use <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer">a
vectorizer</a>
that normalizes the token counts according to the fraction of documents
in which the token appears. That is, it will down-weight tokens that
appear in every document assuming they&#8217;re not special, and vice versa
for infrequent tokens. This particular vectorizer also conveniently
handles the previous preprocessing steps we have outlined. By formatting
our &#8220;remove URLs&#8221; and &#8220;tokenize&#8221; steps as functions, we can simply pass
them into our vectorizer as keyword arguments. Similarly, we can pass in
our custom stopword list for filtering. It&#8217;s worth considering the
interplay between removing stopwords outright (with our
<code class="docutils literal"><span class="pre">my_stopwords</span></code>) and the explicit down-weighting that extremely common
words (like &#8220;the&#8221; and &#8220;les&#8221;) would receive from a TFIDF vectorization.
This is another entry in &#8220;evaluate the effect of the choice for your use
case&#8221; - here, we use both for the increase in computational efficiency
(fewer features).</p>
<p>One common pitfall in feature engineering is generating too many
features for the number of observations. A handy rule-of-thumb from
Google&#8217;s <a class="reference external" href="http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf">Rules of Machine Learning
paper</a> is to
keep the ratio of features to observations at about 1:100. Recall that
we&#8217;re using the literal tokens as features, and we know how many
observations we have based on the earlier unique user count.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">vec</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">replace_urls</span><span class="p">,</span>
                      <span class="n">tokenizer</span><span class="o">=</span><span class="n">my_tokenizer</span><span class="p">,</span>
                      <span class="n">stop_words</span><span class="o">=</span><span class="n">my_stopwords</span><span class="p">,</span>
                      <span class="n">max_features</span><span class="o">=</span><span class="n">unique_user_cnt</span><span class="o">//</span><span class="mi">100</span><span class="p">,</span>
                     <span class="p">)</span>
</pre></div>
</div>
<p>Recall that our &#8220;observations&#8221; are individual users (and their tokenized
bios are our features). Since we collected quite a bit of data, we have
many Tweets by some users. As a result, we must first filter the data
down to one observation per user. While the ordering of our users
doesn&#8217;t matter, we do need to maintain the same ordering between our
user list and the bio list.</p>
<p>The resulting unique user bios can be passed to our vectorizer.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># create one entry per user</span>
<span class="n">unique_user_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">t</span><span class="o">.</span><span class="n">user_id</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">bio</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tweets</span><span class="p">}</span>

<span class="c1"># we need to maintain the same ordering of users and bios</span>
<span class="n">unique_users</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">unique_bios</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">user</span><span class="p">,</span><span class="n">bio</span> <span class="ow">in</span> <span class="n">unique_user_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">unique_users</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">user</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bio</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># special case for empty bios</span>
        <span class="n">bio</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="n">unique_bios</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bio</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># calculate the data matrix</span>
<span class="n">bio_matrix</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">unique_bios</span><span class="p">)</span>

<span class="n">bio_matrix</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="mi">30819</span><span class="n">x308</span> <span class="n">sparse</span> <span class="n">matrix</span> <span class="n">of</span> <span class="nb">type</span> <span class="s1">&#39;&lt;class &#39;</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="s1">&#39;&gt;&#39;</span>
    <span class="k">with</span> <span class="mi">56373</span> <span class="n">stored</span> <span class="n">elements</span> <span class="ow">in</span> <span class="n">Compressed</span> <span class="n">Sparse</span> <span class="n">Row</span> <span class="nb">format</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Note how sparse the data matrix becomes! This is not only common for
text data, but especially so for Tweet text data. There are lots of
little variations in the way people write things on Twitter that
ultimately leads to a high dimensionality.</p>
<p>To make sure we understand the data matrix, we can reassemble it into a
visual format with a little bit of work. Below, we&#8217;ll display the first
few bios in (close to) their original format, and then the same few bios
as they are represented in the document term matrix (over a narrow slice
of features).</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;* original bio text *</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">bio</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_bios</span><span class="p">[:</span><span class="mi">10</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s1">&#39;: &#39;</span><span class="p">,</span> <span class="n">bio</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span>* original bio text *

0 :  Counselor. Psych Grad. 25 Fangirl. (You&#39;ve been warned) Kristen says I&#39;m rad.Twilight. Kristen. Rob. Jamie Dornan. Tom Sturridge. Nic Hoult. Outlander.
1 :  Veterinario, liberal y cuestionador, debilidad: las mujeres inteligentes con car√°cter fuerte. No a las sumisas.
2 :  love
3 :  Everything happens for a reason,learn from it &amp; move on,don&#39;t be bitter about what happened,be happy about will// Hala Madrid- 1/2ofHMS
4 :  CEO/Founder https://t.co/wY9NweIodu Social media for Opera, Ballet, Symphony goes. Club is Free to join. Special events. Tickets Share..Extraordinary Company!
5 :  ELN - #geopolitics #history #SEO #cin√©ma
6 :
7 :  Follow Zesty #Fashion for the freshest #glamour, #redcarpet, #designer #clothing and #celebrity #beauty news.
8 :  Actress, writer, political junkie and Lake Superior worshipper. Block Bernie, Jill, Nomiki peeps and other mouthy Russians.  #HillaryClintonDem #NeverBernie
9 :  ÏûâÏó¨Îãπ Ïó¥ÏÑ±ÎãπÏõê / Ïû°Îçï / ÏßÑÏßÄÏ∂©
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">todense</span><span class="p">(),</span>
              <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()])</span>
 <span class="c1"># experiment by choosing any range of feature indices (alphabetical order)</span>
 <span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">90</span><span class="p">:</span><span class="mi">110</span><span class="p">])</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>facebook</th>
      <th>family</th>
      <th>fan</th>
      <th>fashion</th>
      <th>feminist</th>
      <th>festival</th>
      <th>film</th>
      <th>filmmaker</th>
      <th>films</th>
      <th>find</th>
      <th>first</th>
      <th>follow</th>
      <th>food</th>
      <th>former</th>
      <th>founder</th>
      <th>france</th>
      <th>free</th>
      <th>freelance</th>
      <th>french</th>
      <th>friends</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.385772</td>
      <td>0.0</td>
      <td>0.39021</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.792739</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div><p>Here, we can clearly see the sparsity of the data matrix.</p>
<p>There are other approaches to text modeling that address the issue of
sparsity like <a class="reference external" href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/">word and document
embeddings</a>.
But, those are outside the scope of this example.</p>
<p>Now we have a representation of our user-text data and we can use this
as an input to our clustering algorithms.</p>
</div>
</div>
<div class="section" id="selecting-and-tuning-a-model">
<h1>Selecting and tuning a model<a class="headerlink" href="#selecting-and-tuning-a-model" title="Permalink to this headline">¬∂</a></h1>
<p>There are <a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html">many types of clustering
algorithms</a>
available off-the-shelf through libraries like <code class="docutils literal"><span class="pre">sklearn</span></code>. While we
aren&#8217;t going to work through all of them in this demo, we&#8217;ll compare a
couple different algorithms.</p>
<p><strong>KMeans</strong></p>
<p><a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html#k-means">KMeans</a>
is a common choice because it is very fast for moderate amounts of data.
Like most algorithms, <code class="docutils literal"><span class="pre">KMeans</span></code> has parameters that need to be chosen
appropriately. In this case, that parameter is <code class="docutils literal"><span class="pre">k</span></code>, the number of
clusters in our data.</p>
<p>In unsupervised learning, we can&#8217;t easily calculate (and optimize) an
accuracy score, so we have to use other techniques to compare models to
one another for selecting <code class="docutils literal"><span class="pre">k</span></code>. Since we don&#8217;t know this number <em>a
priori</em>, one technique involves comparing the value of some quality
metric across a range of potential <code class="docutils literal"><span class="pre">k</span></code>s. There are a number of
<a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation">known quality
metrics</a>,
of which we&#8217;ll use just a couple: <a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient">silhouette
score</a>
(larger is better) and inertia (smaller is better).</p>
<p>We typically want to survey a wide, course range of <code class="docutils literal"><span class="pre">k</span></code>s, and then
possibly narrow in to evaluate a smaller range around the best
identified. We&#8217;ll only demonstrate the first step here. This process
takes a lot of processing time, but can be sped up (for k-means, at
least) with more processor cores.</p>
<p>‚ö†Ô∏è <strong>Warning</strong> ‚ö†Ô∏è</p>
<p>The code below may take a few minutes to run on a laptop. If you get
impatient working through this demo, you can either reduce the number of
k values compared to just a couple, or significantly reduce the total
amount of data (<code class="docutils literal"><span class="pre">max_results</span></code> in the query).</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="c1"># compare a broad range of ks to start</span>
<span class="n">ks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>


<span class="c1"># track a couple of metrics</span>
<span class="n">sil_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># fit the models, save the evaluation metrics from each run</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">:</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;fitting model for </span><span class="si">{}</span><span class="s1"> clusters&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">labels_</span>
    <span class="n">sil_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># plot the quality metrics for inspection</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">inertias</span><span class="p">,</span> <span class="s1">&#39;o--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;inertia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;kmeans parameter search&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">sil_scores</span><span class="p">,</span> <span class="s1">&#39;o--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;silhouette score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;k&#39;</span><span class="p">);</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">WARNING</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">fitting</span> <span class="n">model</span> <span class="k">for</span> <span class="mi">2</span> <span class="n">clusters</span>
</pre></div>
</div>
<p>Unfortunately, these metrics will rarely tell you the best answer for
how many clusters are appropriate. Both of these plotted metrics will
asymptotically approach their &#8220;ideal&#8221; value, and so the practitioner is
typically advised to choose the value in <a class="reference external" href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#The_elbow_method">&#8220;the
elbow&#8221;</a>
of these curves - that is, the point at which the returns seem to be
diminishing for an increase in <code class="docutils literal"><span class="pre">k</span></code>.</p>
<p>Based on that pair of figures, it looks like <code class="docutils literal"><span class="pre">k</span> <span class="pre">~</span> <span class="pre">200</span></code> is a good place
to start. To be a bit more careful, we might consider running the same
comparison over a narrower range of <code class="docutils literal"><span class="pre">k</span></code> values between, say, 10 and
500. Furthermore, you&#8217;ll want to consider - and incorporate - other
external constraints on your model. Maybe the number of user clusters
according to the elbow is too many (or too few) to reasonably consider
given the question you&#8217;re trying to answer with the data.</p>
<p>For now, let&#8217;s go with our best k value, train a new model on all of our
data, and carry on with our analysis.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">best_k</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">km_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">best_k</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">km_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="inspecting-model-results">
<h1>Inspecting model results<a class="headerlink" href="#inspecting-model-results" title="Permalink to this headline">¬∂</a></h1>
<p>We now have a trained model of users and the clusters to which they
belong. At this point, we should inspect the resulting clusters to
understand what we&#8217;ve discovered. There are a number of ways to do this
- here we&#8217;ll look at a couple.</p>
<p><strong>Population sizes</strong></p>
<p>A good first thing to check is simply the population of each cluster.
You can compare these numbers to any prior knowledge you have about the
users, or to identify unexpected results.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))),</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;cluster label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;population sizes with </span><span class="si">{}</span><span class="s1"> clusters&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_k</span><span class="p">));</span>

<span class="c1"># truncate y axis to see the rest better</span>
<span class="c1"># (comment out to see the peak value for the largest cluster)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1000</span><span class="p">);</span>
</pre></div>
</div>
<p>We appear to have one cluster with a very large population, and the rest
with relatively consistent populations. Is that expected? We don&#8217;t have
any particular reason to think that the user clusters would be similarly
sized.</p>
<p>Having one particularly large cluster, however, is a common result.
While it <em>could</em> mean that there are many thousands of very similar
users, it often indicates that we&#8217;re not doing a good job of
differentiating those users - possibly because our data on them is just
not very interesting. While there isn&#8217;t any obvious conclusion at this
point, we&#8217;ll want to consider looking into that particular cluster more
carefully to see what&#8217;s going on there.</p>
<div class="section" id="cluster-text-association">
<h2>Cluster-text association<a class="headerlink" href="#cluster-text-association" title="Permalink to this headline">¬∂</a></h2>
<p>For another inspection technique, recall that the observations (users)
were clustered in a parameter space comprising the words used in their
bio fields. In the KMeans algorithm, the resulting representation of
these clusters are the coordinates of each cluster&#8217;s centroid in that
token space. Thus, another way to inspect our results is to ask: for
each cluster centroid, which token vectors have the largest projection
onto that centroid? That is, which tokens are most strongly associated
with each cluster?</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">strongest_features</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to display a simple text representation of the top-k most</span>
<span class="sd">    important features in our fit model and vectorizer.</span>

<span class="sd">    model: sklearn model</span>
<span class="sd">    vectorizer: sklearn vectorizer</span>
<span class="sd">    topk: k numbers of words to get per cluster</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># these parts are model-independent</span>
    <span class="n">m_name</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
    <span class="c1"># different calculations per model type</span>
    <span class="k">if</span> <span class="n">m_name</span> <span class="ow">is</span> <span class="s1">&#39;KMeans&#39;</span><span class="p">:</span>
        <span class="n">relevant_labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>
        <span class="n">centroids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">this_label</span> <span class="ow">in</span> <span class="n">relevant_labels</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cluster </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">this_label</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">centroids</span><span class="p">[</span><span class="n">this_label</span><span class="p">,</span> <span class="p">:</span><span class="n">topk</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">ind</span><span class="p">]),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">m_name</span> <span class="ow">is</span> <span class="s1">&#39;HDBSCAN&#39;</span><span class="p">:</span>
        <span class="c1"># ignore noise labels</span>
        <span class="n">relevant_labels</span> <span class="o">=</span> <span class="p">[</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="p">]</span>
        <span class="k">for</span> <span class="n">this_label</span> <span class="ow">in</span> <span class="n">relevant_labels</span><span class="p">:</span>
            <span class="n">matching_rows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">hdbs</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="n">this_label</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">coeff_sums</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">[</span><span class="n">matching_rows</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">A1</span>
            <span class="n">sorted_coeff_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">coeff_sums</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cluster </span><span class="si">{}</span><span class="s1">: &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">this_label</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sorted_coeff_idxs</span><span class="p">[:</span><span class="n">topk</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;This helper method currently only supports KMeans and HDBSCAN models&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">strongest_features</span><span class="p">(</span><span class="n">km_model</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<p>Recall that <code class="docutils literal"><span class="pre">&lt;-URL-&gt;</span></code> is the token for &#8220;there was a URL here&#8221;.</p>
<p>The volume of output here is large, so it&#8217;s pretty challenging to read
and parse - can we really distinguish between any set of these word
lists? This is one of the tricky parts of unsupervised learning - there
isn&#8217;t always a &#8220;best&#8221; choice for selecting these parameters.</p>
<p>For the sake of demonstration, let&#8217;s see what the results look like if
we use the same preprocessing steps but limit the cluster count to a
much smaller number. <strong>Note that this is arbitrary!</strong> Ideally, you will
reflect on how the choice of cluster count is constrained by your use
case, and intended use of the resulting data.</p>
<p>Once we have the trained model, we can look at the same diagnostics.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">smaller_k</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">km_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">smaller_k</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">km_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bio_matrix</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))),</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;cluster label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;k=</span><span class="si">{}</span><span class="s1"> cluster populations&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">smaller_k</span><span class="p">));</span>

<span class="c1"># truncating the axis again!</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3000</span><span class="p">);</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">strongest_features</span><span class="p">(</span><span class="n">km_model</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we can see some distinctions in the first (strongest) terms: news,
cine, student, etc., as well as some apparently language-based, and
emoji-heavy clusters.</p>
<p>Since this particular view of tokens is centroid-specific, we&#8217;ve lost
the context of the original text. We can also invert the query and look
at a sample of original-text bios that were assigned to a particular
cluster.</p>
<p>Let&#8217;s look at the full texts from a cluster that seems interesting. You
can choose any of the cluster numbers from the output above.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cluster_sample</span><span class="p">(</span><span class="n">orig_text</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">preview</span><span class="o">=</span><span class="mi">15</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to display original bio for</span>
<span class="sd">    those users modeled in cluster `idx`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">labels_</span> <span class="o">==</span> <span class="n">idx</span><span class="p">)[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">orig_text</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="s1">&#39; &#39;</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">preview</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;( &gt;&gt;&gt; truncated preview &lt;&lt;&lt; )&#39;</span><span class="p">)</span>
            <span class="k">break</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># feel free to modify this</span>
<span class="n">interest_idx</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">cluster_sample</span><span class="p">(</span><span class="n">unique_bios</span><span class="p">,</span> <span class="n">km_model</span><span class="p">,</span> <span class="n">interest_idx</span><span class="p">)</span>
</pre></div>
</div>
<p>Based on this sample of user bios, it does look like we&#8217;ve identified a
group of users who self-identify quite similarly. Importantly, however,
note the range of other qualities that are also represented - sometimes
they span politics, media, and geography.</p>
<p>If you were interested in looking at additional bio patterns <em>within</em>
that cluster, you could use these modeled labels as a filter and
calculate a similar rough n-gram list as we did earlier for Tweet text.</p>
<p>In addition to using the clusters to identify relevant groups of users,
you could also decide that a cluster represents a source of noise to be
filtered out in the rest of your analysis. For example, perhaps you want
to filter out users who seem to self-describe in a particular language
or from a particular country.</p>
<p>Furthermore, you could apply more advanced forms of topic modeling to
these groups - we&#8217;ve only mentioned the simplest form: n-gram counting.</p>
</div>
<div class="section" id="visualization">
<h2>Visualization<a class="headerlink" href="#visualization" title="Permalink to this headline">¬∂</a></h2>
<p>Finally, we might want to look at a graphical representation of our
results somehow to get another check on what we discovered. Typically in
text-based models, the dimensionality of the feature space is too high
for direct visualization techniques. While we cannot simply plot all the
users in the token space and color them by their clusters, we can do
something similar if we apply some dimensionality reduction.</p>
<p>One popular approach for doing this is to use
<a class="reference external" href="http://scikit-learn.org/stable/modules/manifold.html#t-sne">t-SNE</a>
to create a 2- or 3-dimensional view of the data. t-SNE attempts to
maintain - in the lower-dimensional representation - some of the
relative structure present in the original, high-dimensionality data.
Note that this technique is helpful for visualization but would be a
problematic step for the middle of a data processing pipeline e.g. prior
to clustering (<a class="reference external" href="https://distill.pub/2016/misread-tsne/">t-SNE is a non-deterministic
algorithm</a>, so you&#8217;ll lose
any reproducibility).</p>
<p>The <code class="docutils literal"><span class="pre">sklearn</span></code> implementation of t-SNE is still somewhat slow, and the
one used here (<code class="docutils literal"><span class="pre">MulticoreTSNE</span></code>) can be <a class="reference external" href="https://github.com/DmitryUlyanov/Multicore-TSNE#benchmark">quite a bit
faster</a>.
For the size of data we have here, it will still take around ten minutes
to fit this reduction on a laptop.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">maybe_fit_tsne</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">file</span> <span class="o">=</span> <span class="s2">&quot;data/bio_matrix_2d.npy&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">bio_matrix_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;loading cached TSNE file&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Fitting TSNE&quot;</span><span class="p">)</span>
        <span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">bio_matrix_2d</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">bio_matrix</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>

        <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">bio_matrix_2d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bio_matrix_2d</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">tsne_file</span> <span class="o">=</span> <span class="s2">&quot;data/bio_matrix_2d.npy&quot;</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">bio_matrix_2d</span> <span class="o">=</span> <span class="n">maybe_fit_tsne</span><span class="p">(</span><span class="n">tsne_file</span><span class="p">)</span>
</pre></div>
</div>
<p>In two dimensions, we can plot the data. Even better, we can add
additional visual cues to inform our data inspection like coloring
according to cluster labels, and adding the original text content for
interactive exploration. For this, we can use some of the handy
functionality of the bokeh plotting library. For more context on the
options within that library, <a class="reference external" href="https://bokeh.pydata.org/en/latest/">refer to the
documentation</a>.</p>
<p>The one extra step we have to take, however, is coercing our various
pieces of data into a dataframe that plays nice with the library.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_plottable_df</span><span class="p">(</span><span class="n">users</span><span class="p">,</span> <span class="n">bios</span><span class="p">,</span> <span class="n">two_d_coords</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Combine the necessary pieces of data to create a data structure that plays</span>
<span class="sd">    nicely with the our 2d tsne chart.</span>

<span class="sd">    Note: assumes that all argument data series</span>
<span class="sd">    are in the same order e.g. the first user, bio, coords, and label</span>
<span class="sd">    all correspond to the same user.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># set up color palette</span>
    <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s1">&#39;hls&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
    <span class="n">color_lookup</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))}</span>
    <span class="c1"># combine data into a single df</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;uid&#39;</span><span class="p">:</span> <span class="n">users</span><span class="p">,</span>
                       <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">bios</span><span class="p">,</span>
                       <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span>
                       <span class="s1">&#39;x_val&#39;</span><span class="p">:</span> <span class="n">two_d_coords</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
                       <span class="s1">&#39;y_val&#39;</span><span class="p">:</span> <span class="n">two_d_coords</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
                      <span class="p">})</span>
    <span class="c1"># convert labels to colors</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">color_lookup</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">labels</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">df</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># pass in the cluster assignments from the kmeans model</span>
<span class="n">km_plottable_bios</span> <span class="o">=</span> <span class="n">get_plottable_df</span><span class="p">(</span><span class="n">unique_users</span><span class="p">,</span> <span class="n">unique_bios</span><span class="p">,</span> <span class="n">bio_matrix_2d</span><span class="p">,</span> <span class="n">km_model</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>

<span class="n">km_plottable_bios</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_tsne</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;t-SNE plot&#39;</span><span class="p">):</span>
    <span class="c1"># add our DataFrame as a ColumnDataSource for Bokeh</span>
    <span class="n">plot_data</span> <span class="o">=</span> <span class="n">ColumnDataSource</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="c1"># configure the chart</span>
    <span class="n">tsne_plot</span> <span class="o">=</span> <span class="n">figure</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> <span class="n">plot_width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">plot_height</span><span class="o">=</span><span class="mi">700</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;pan, box_zoom, reset&#39;</span><span class="p">))</span>
    <span class="c1"># add a hover tool to display words on roll-over</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">add_tools</span><span class="p">(</span>
        <span class="n">HoverTool</span><span class="p">(</span><span class="n">tooltips</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;&lt;div style=&quot;width: 400px;&quot;&gt;(@label) @text&lt;/div&gt;&quot;&quot;&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># draw the words as circles on the plot</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">circle</span><span class="p">(</span><span class="s1">&#39;x_val&#39;</span><span class="p">,</span> <span class="s1">&#39;y_val&#39;</span><span class="p">,</span>
                     <span class="n">source</span><span class="o">=</span><span class="n">plot_data</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s1">&#39;color&#39;</span><span class="p">,</span>
                     <span class="n">line_alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                     <span class="n">fill_alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                     <span class="n">hover_line_color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="c1"># configure visual elements of the plot</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">text_font_size</span> <span class="o">=</span> <span class="s1">&#39;12pt&#39;</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">visible</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">visible</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">grid</span><span class="o">.</span><span class="n">grid_line_color</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">tsne_plot</span><span class="o">.</span><span class="n">outline_line_color</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">tsne_plot</span>
</pre></div>
</div>
<p>For rendering in a static webpage and not in a notebook, I am sampling
from our <code class="docutils literal"><span class="pre">km_plottable_bios</span></code> dataframe. If you are running this
notebook live, feel free to render the full dataframe.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">show</span><span class="p">(</span><span class="n">plot_tsne</span><span class="p">(</span><span class="n">km_plottable_bios</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">),</span>
               <span class="s1">&#39;t-sne projection of kmeans-clustered users [&quot;(cluster #) bio&quot;]&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>We can use the mouseover text to explore the color-coded clusters. The
current configuration of the mouseover text is &#8220;(<code class="docutils literal"><span class="pre">&lt;cluster</span> <span class="pre">number&gt;</span></code>)
<code class="docutils literal"><span class="pre">&lt;bio</span> <span class="pre">text&gt;</span></code>&#8221;. Some of the text patterns that I observed in the
clusters above:</p>
<ul class="simple">
<li>broad, language-based clusters (Spanish, French, etc.)</li>
<li>&#8220;breaking news&#8221; and news account clusters (in multiple languages)</li>
<li>emoji-heavy clusters, including one that seems tightly clustered
around the ‚ù§Ô∏è (&#8220;red heart&#8221;) character</li>
<li>other clusters that seem weighted on a varying sets of specific
unicode characters</li>
<li>&#8220;actor&#8221; and &#8220;director&#8221; clusters</li>
<li>the really large, amorphous cluster without an obvious pattern</li>
</ul>
<p>So, what can we learn from this view?</p>
<p>First off, the last cluster mentioned (the large, indistinct cluster)
appears to comprise - among other things - a mix of empty bios (blank
strings) and low-frequency words that weren&#8217;t important in the model.
This is often the case when dealing with user-generated text. More data
(more observed users) might mitigate this risk by contributing more
signal to those words, but there is no guarantee.</p>
<p>Second, handling unicode characters (possibly multi-byte ones) is
important! Recall that we stripped most of the punctuation-only tokens
from our data before fitting a model - now we can see that we only did
so for ASCII punctuation. Depending on your model goals, it might be
useful to also specify a range of higher-value unicode characters to add
as stopwords. Or, alternatively, handle characters like emoji in a
special preprocessing step.</p>
<p>Perhaps at this point you&#8217;ve decided this model is good enough for your
use case and you set out to learn more about the clusters of interest -
maybe for an outreach campaign, or to better understand who&#8217;s paying
attention to the events at the Cannes Film Festival.</p>
<p>Alternatively, perhaps you&#8217;re skeptical, or just not satisfied with the
results of this effort and you&#8217;d like to try another type of model. Next
up, we&#8217;ll do a quick iteration with a different type of model.</p>
</div>
</div>
<div class="section" id="model-iteration">
<h1>Model iteration<a class="headerlink" href="#model-iteration" title="Permalink to this headline">¬∂</a></h1>
<div class="section" id="hdbscan">
<h2>HDBSCAN<a class="headerlink" href="#hdbscan" title="Permalink to this headline">¬∂</a></h2>
<p>While fast and simple, <code class="docutils literal"><span class="pre">KMeans</span></code> is not the ideal model for text-based
clustering. There are a number of reasons why you might choose a
different algorithm - most of which boil down to <a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html">bad assumptions made
of the input
data</a>.</p>
<p>Let&#8217;s consider how we would proceed with another type of clustering
model. <code class="docutils literal"><span class="pre">HDBSCAN</span></code> is a hierarchical model that also allows observations
to be classified as noise. These are just two of many handy features,
many more of which are described in the <code class="docutils literal"><span class="pre">`HDBSCAN</span></code>
docs &lt;<a class="reference external" href="https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html">https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html</a>&gt;`__.</p>
<p>One of the convenient features of HDBSCAN is that the main user-chosen
parameter is effectively &#8220;what is the minimum number of observations you
would consider a &#8216;cluster&#8217;?&#8221;. Again, this is a parameter that you have
to select based on knowledge of your specific problem and constraints.
One related, and particularly useful, feature of HDBSCAN is that
clusters of points below this threshold will be labeled as &#8220;noise&#8221;
instead of being assigned to a cluster. For now, let&#8217;s assume that once
we have 100 people that are pretty similar, that&#8217;s officially a real
cluster.</p>
<p>After fitting this new model, we&#8217;ll quickly run through the same
inspection techniques we used earlier. Note that this model takes longer
to fit than the KMeans model - expect a few minutes - and will cache
some of the calculations in the <code class="docutils literal"><span class="pre">data/</span></code> location for faster use later.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">maybe_fit_hdbscan</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;data/hdbscan.pkl&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">hdbs</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;loading cached HDBSCAN model&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;fitting HDBSCAN model&quot;</span><span class="p">)</span>
        <span class="n">hdbs</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_cluster_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                               <span class="n">prediction_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">core_dist_n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                               <span class="n">memory</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
        <span class="n">hdbs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bio_matrix</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>
        <span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">hdbs</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">hdbs</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">hdbscan_file</span> <span class="o">=</span> <span class="s1">&#39;data/hdbscan.pkl&#39;</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">hdbs</span> <span class="o">=</span> <span class="n">maybe_fit_hdbscan</span><span class="p">(</span><span class="n">hdbscan_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="populations-sizes">
<h2>Populations sizes<a class="headerlink" href="#populations-sizes" title="Permalink to this headline">¬∂</a></h2>
<p>Because of the differences in the models, we have to extract some of the
features slightly differently. Note, as well, that with HDBSCAN we don&#8217;t
specify the number of clusters <em>a priori</em> - we can see how many were
found once it&#8217;s fit, though.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># get the population sizes</span>
<span class="n">label_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">hdbs</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">label_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="c1"># draw the chart</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_counts</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;cluster label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;population sizes (</span><span class="si">{}</span><span class="s1"> clusters found by hdbscan)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_counts</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">));</span>
</pre></div>
</div>
<p>Recall that in the <a class="reference external" href="https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html">HDBSCAN cluster
assignments</a>,
the &#8220;noise&#8221; points (which don&#8217;t belong in any cluster) are all given a
cluster of <code class="docutils literal"><span class="pre">-1</span></code>. Following this model fit, we can see that a
significant number of the users were not assigned to a real cluster -
they were instead labeled as noise.</p>
</div>
<div class="section" id="id1">
<h2>Cluster-text association<a class="headerlink" href="#id1" title="Permalink to this headline">¬∂</a></h2>
<p>Similarly to how we looked at the words that were most strongly
associated with KMeans clusters, we can also inspect the features most
central in our HDBSCAN clusters. The calculation is a bit different, but
the idea is still the same.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">strongest_features</span><span class="p">(</span><span class="n">hdbs</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<p>Among other things, this time we observe that all of the identified
clusters frequently have a URL replacement in the text.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># feel free to modify this</span>
<span class="n">interest_idx</span> <span class="o">=</span> <span class="mi">6</span>

<span class="n">cluster_sample</span><span class="p">(</span><span class="n">unique_bios</span><span class="p">,</span> <span class="n">hdbs</span><span class="p">,</span> <span class="n">interest_idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2>Visualization<a class="headerlink" href="#id2" title="Permalink to this headline">¬∂</a></h2>
<p>We can also use a similar visualization template to inspect our results
in graphical form. We&#8217;ll use the <code class="docutils literal"><span class="pre">get_plottable_df()</span></code> helper function
again, along with the same list of users, bios, and even the same
two-dimensional reduction of the data matrix. As a result, the x and y
positions of the users should remain the same (remember that the t-SNE
model was based on the vectorized text data matrix, not any particular
clustering of it), but we&#8217;ll pass in the user cluster labels (used for
chart colors) generated by our HDBSCAN model this time. As before, for
friendly rendering of this post in your browser, I&#8217;m only plotting a
sample of 5000 user bios here.</p>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="c1"># pass in the cluster assignments from the hdbscan model</span>
<span class="n">hdb_plottable_bios</span> <span class="o">=</span> <span class="n">get_plottable_df</span><span class="p">(</span><span class="n">unique_users</span><span class="p">,</span> <span class="n">unique_bios</span><span class="p">,</span> <span class="n">bio_matrix_2d</span><span class="p">,</span> <span class="n">hdbs</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>

<span class="n">hdb_plottable_bios</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div class="code python highlight-default"><div class="highlight"><pre><span></span><span class="n">show</span><span class="p">(</span><span class="n">plot_tsne</span><span class="p">(</span><span class="n">hdb_plottable_bios</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">),</span>
               <span class="s1">&#39;t-sne projection of hdbscan-clustered users [&quot;(cluster #) bio&quot;]&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>The specific color-cluster pairs have no meaning (i.e. a blue-ish group
in one chart has nothing to do with the blue-ish group in the second
chart). Still, we can see both some similarities, as well as some
differences in how the clusters (colors) are distributed across the
chart. This type of visualization is a helpful exploratory tool for
learning more about <em>how</em> users ended up in a particular cluster.</p>
<p>Given these two algorithm choices, is one obviously better than the
other? It&#8217;s tough to say at this point. In unsupervised learning tasks
like this one, we have to assess our results against other constraints
(is simplicity important? Do we value the input data assumptions of one
model over the other?), or outside metrics (did one approach lead to
higher conversion rates?).</p>
</div>
</div>
<div class="section" id="conclusion">
<h1>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¬∂</a></h1>
<p>Twitter is a valuable source of data about what&#8217;s happening in the
world. The rich data available through the suite of APIs provides a
detailed view into the people and content on the platform. In this
tutorial, we worked through an end-to-end example workflow - from
collecting data from the Twitter API, to creating and inspecting a model
of Twitter users. Along the way, we highlighted how to identify and use
relevant elements of the data payload, how to convert that data into a
format compatible with many machine learning libraries, and how to
inspect the resulting models for interpretability. More specifically, we
created query rules relevant to an event, collected matching JSON data,
parsed that data to extract user-specific information, applied
clustering algorithms to the text data, and looked at both textual and
graphical model output representations for interpretation.</p>
<p>Along the way, we highlighted additional opportunities to explore
variations on the specific choices we demonstrated. One of the most
important take-aways from this demo is that there are few <strong>strictly
correct</strong> choices about the data pipeline, or the model results. Rather,
the best strategy is one of experimentation and subsequent evaluation
against metrics that matter for you. Furthermore, we used a form of
unsupervised learning (clustering), which often requires a human in the
loop to review the outputs and assess for suitability. By creating good
systems for review and feedback, you can experiment and reach a valuable
outcome or result sooner.</p>
</div>


    </div>
      
  </div>
</div>
    
      <!-- Global site tag (gtag.js) - Google Analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-30775-108"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-30775-108'); </script>
      
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2018, Twitter.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.5.6.<br/>
    </p>
  </div>
</footer>
    


  </body>
</html>