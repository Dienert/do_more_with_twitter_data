{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with the API within a Python program is straightforward both for Premium and Enterprise clients.\n",
    "\n",
    "We'll assume that credentials are in the default location, `~/.twitter_keys.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enterprise setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enterprise_search_args = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_enterprise\",\n",
    "                                          env_overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premium Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "premium_search_args = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                       yaml_key=\"search_tweets_premium_30day\",\n",
    "                                       env_overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function that formats search API rules into valid json queries called `gen_rule_payload`. It has sensible defaults, such as pulling more Tweets per call than the default 100 (but note that a sandbox environment can only have a max of 100 here, so if you get errors, please check this) not including dates, and defaulting to hourly counts when using the counts api. Discussing the finer points of generating search rules is out of scope for these examples; I encourage you to see the docs to learn the nuances within, but for now let's see what a rule looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\":\"beyonce\",\"maxResults\":100}\n"
     ]
    }
   ],
   "source": [
    "rule = gen_rule_payload(\"beyonce\", results_per_call=100) # testing with a sandbox account\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rule will match tweets that have the text `beyonce` in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point, there are two ways to interact with the API. There is a quick method to collect smaller amounts of Tweets to memory that requires less thought and knowledge, and interaction with the `ResultStream` object which will be introduced later.\n",
    "\n",
    "\n",
    "## Fast Way\n",
    "\n",
    "We'll use the `search_args` variable to power the configuration point for the API. The object also takes a valid PowerTrack rule and has options to cutoff search when hitting limits on both number of Tweets and API calls.\n",
    "\n",
    "We'll be using the `collect_results` function, which has three parameters.\n",
    "\n",
    "- rule: a valid PowerTrack rule, referenced earlier\n",
    "- max_results: as the API handles pagination, it will stop collecting when we get to this number\n",
    "- result_stream_args: configuration args that we've already specified.\n",
    "\n",
    "\n",
    "For the remaining examples, please change the args to either premium or enterprise depending on your usage.\n",
    "\n",
    "Let's see how it goes:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
